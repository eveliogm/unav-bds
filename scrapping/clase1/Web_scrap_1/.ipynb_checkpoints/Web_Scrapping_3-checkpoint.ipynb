{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://forecast.weather.gov/MapClick.php?lat=37.7772&lon=-122.4168#.Wr1tO4jwY2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "import urllib.request as urllib2\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with Python - Beautifulsoup\n",
    "\n",
    "http://www.tulane.edu/~howard/NLP/webpages.html<br>\n",
    "https://www.dataquest.io/blog/web-scraping-tutorial-python/<br>\n",
    "\n",
    "When we visit a web page, our web browser makes a request to a web server. This request is called a GET request, since we're getting files from the server. The server then sends back files that tell our browser how to render the page for us. The files fall into a few main types:\n",
    "\n",
    "HTML — contain the main content of the page. <br>\n",
    "CSS — add styling to make the page look nicer. <br>\n",
    "JS — Javascript files add interactivity to web pages. <br>\n",
    "Images — image formats, such as JPG and PNG allow web pages to show pictures.\n",
    "\n",
    "After our browser receives all the files, it renders the page and displays it to us. There's a lot that happens behind the scenes to render a page nicely, but we don't need to worry about most of it when we're web scraping. When we perform web scraping, we're interested in the main content of the web page, so we look at the HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML\n",
    "HyperText Markup Language (HTML) is a language that web pages are created in. HTML isn't a programming language, like Python. Instead, it's a markup language that tells a browser how to layout content. HTML allows you to do similar things to what you do in a word processor like Microsoft Word: make text bold, create paragraphs, and so on. Because HTML isn't a programming language, it isn't nearly as complex as Python.\n",
    "\n",
    "Right inside an html tag, we put two other tags, the head tag, and the body tag. The main content of the web page goes into the body tag. The head tag contains data about the title of the page, and other information that generally isn't useful in web scraping:\n",
    "\n",
    "![title](bsoup1.png)\n",
    "\n",
    "\n",
    "You may have noticed above that we put the head and body tags inside the html tag. In HTML, tags are nested, and can go inside other tags.\n",
    "\n",
    "\n",
    "\n",
    "Tags have commonly used names that depend on their position in relation to other tags:\n",
    "\n",
    "child — a child is a tag inside another tag. So the two p tags above are both children of the body tag.\n",
    "parent — a parent is the tag another tag is inside. Above, the html tag is the parent of the body tag.\n",
    "sibiling — a sibiling is a tag that is nested inside the same parent as another tag. For example, head and body are siblings, since they're both inside html. Both p tags are siblings, since they're both inside body.\n",
    "\n",
    "\n",
    "Here are a few common html tags:\n",
    "\n",
    "p - paragraph <br>\n",
    "a - indicates a link <br>\n",
    "div - indicates a division, or area, of the page. <br>\n",
    "b - bolds any text inside. <br>\n",
    "i - italicizes any text inside. <br>\n",
    "table - creates a table. <br>\n",
    "form - creates an input form. <br>\n",
    "\n",
    "This is the complete list of elements you might find: <br>\n",
    "https://developer.mozilla.org/en-US/docs/Web/HTML/Element\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: what indicates the h1 tag?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## requests\n",
    "\n",
    "The requests library will make a GET request to a web server, which will download the HTML contents of a given web page for us. \n",
    "\n",
    "status_code indicates whether the download was successful or not.\n",
    "content has the html downloaded content.\n",
    "\n",
    "resources: <br>\n",
    "http://docs.python-requests.org/en/master/ <br>\n",
    "http://www.dataquest.io/blog/python-api-tutorial/ <br>\n",
    "http://docs.python-requests.org/en/master/user/quickstart/#response-content <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.example.com'\n",
    "#headers = {'User-Agent' : 'OpenGraph Extractor (YOUR_EMAIL_HERE)'}\n",
    "url = requests.get(url)#, None, headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beautifulsoup\n",
    "\n",
    "Beautifulsoup is essentialy a parser for html content. In fact, you can specify the parser you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(url.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_node = soup.find('meta', property = 'og:description')\n",
    "if description_node:\n",
    "    description = description_node.get('content')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now select all the elements at the top level of the page using the children property of soup. Note that children returns a list generator, so we need to call the list function on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doctype html', '\\n', <html>\n",
       " <head>\n",
       " <title>Example Domain</title>\n",
       " <meta charset=\"utf-8\"/>\n",
       " <meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-type\"/>\n",
       " <meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
       " <style type=\"text/css\">\n",
       "     body {\n",
       "         background-color: #f0f0f2;\n",
       "         margin: 0;\n",
       "         padding: 0;\n",
       "         font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
       "         \n",
       "     }\n",
       "     div {\n",
       "         width: 600px;\n",
       "         margin: 5em auto;\n",
       "         padding: 2em;\n",
       "         background-color: #fdfdff;\n",
       "         border-radius: 0.5em;\n",
       "         box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n",
       "     }\n",
       "     a:link, a:visited {\n",
       "         color: #38488f;\n",
       "         text-decoration: none;\n",
       "     }\n",
       "     @media (max-width: 700px) {\n",
       "         div {\n",
       "             margin: 0 auto;\n",
       "             width: auto;\n",
       "         }\n",
       "     }\n",
       "     </style>\n",
       " </head>\n",
       " <body>\n",
       " <div>\n",
       " <h1>Example Domain</h1>\n",
       " <p>This domain is for use in illustrative examples in documents. You may use this\n",
       "     domain in literature without prior coordination or asking for permission.</p>\n",
       " <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\n",
       " </div>\n",
       " </body>\n",
       " </html>, '\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(soup.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[bs4.element.Doctype,\n",
       " bs4.element.NavigableString,\n",
       " bs4.element.Tag,\n",
       " bs4.element.NavigableString]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type of each element in the list:\n",
    "[type(item) for item in list(soup.children)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, all of the items are BeautifulSoup objects. The first is a Doctype object, which contains information about the type of the document. The second is a NavigableString, which represents text found in the HTML document. The final item is a Tag object, which contains other nested tags. The most important object type, and the one we'll deal with most often, is the Tag object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now niceliy print the content with prettify, a beautifulsoup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE doctype html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Example Domain\n",
      "  </title>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-type\"/>\n",
      "  <meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n",
      "  <style type=\"text/css\">\n",
      "   body {\n",
      "        background-color: #f0f0f2;\n",
      "        margin: 0;\n",
      "        padding: 0;\n",
      "        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
      "        \n",
      "    }\n",
      "    div {\n",
      "        width: 600px;\n",
      "        margin: 5em auto;\n",
      "        padding: 2em;\n",
      "        background-color: #fdfdff;\n",
      "        border-radius: 0.5em;\n",
      "        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n",
      "    }\n",
      "    a:link, a:visited {\n",
      "        color: #38488f;\n",
      "        text-decoration: none;\n",
      "    }\n",
      "    @media (max-width: 700px) {\n",
      "        div {\n",
      "            margin: 0 auto;\n",
      "            width: auto;\n",
      "        }\n",
      "    }\n",
      "  </style>\n",
      " </head>\n",
      " <body>\n",
      "  <div>\n",
      "   <h1>\n",
      "    Example Domain\n",
      "   </h1>\n",
      "   <p>\n",
      "    This domain is for use in illustrative examples in documents. You may use this\n",
      "    domain in literature without prior coordination or asking for permission.\n",
      "   </p>\n",
      "   <p>\n",
      "    <a href=\"https://www.iana.org/domains/example\">\n",
      "     More information...\n",
      "    </a>\n",
      "   </p>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract a single tag, we can simply use the find_all method, which will find all the instances of a tag on a page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>This domain is for use in illustrative examples in documents. You may use this\n",
       "     domain in literature without prior coordination or asking for permission.</p>,\n",
       " <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that find_all returns a list, so we'll have to loop through, or use list indexing, it to extract text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This domain is for use in illustrative examples in documents. You may use this\\n    domain in literature without prior coordination or asking for permission.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p')[0].get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you instead only want to find the first instance of a tag, you can use the find method, which will return a single BeautifulSoup object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>This domain is for use in illustrative examples in documents. You may use this\n",
       "    domain in literature without prior coordination or asking for permission.</p>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### beautifulsoup - Searching for tags by class and id\n",
    "\n",
    "Classes and ids are used by CSS to determine which HTML elements to apply certain styles to. We can also use them when scraping to specify specific elements we want to scrape. \n",
    "\n",
    "We can use the find_all method to search for items by class or by id. In the below example, we'll search for any p tag that has the class period-name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p', class_='class_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of specifying a tag, you can also search for any tag which mets your requirements as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(class_=\"class_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or even search elements by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(id=\"id_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSS\n",
    "\n",
    "Another way of seraching items is through CSS selectors. These selectors are how the CSS language allows developers to specify HTML tags to style. Here are some examples:\n",
    "\n",
    "p a — finds all a tags inside of a p tag. <br>\n",
    "body p a — finds all a tags inside of a p tag inside of a body tag. <br>\n",
    "html body — finds all body tags inside of an html tag. <br>\n",
    "p.outer-text — finds all p tags with a class of outer-text.  <br>\n",
    "p#first — finds all p tags with an id of first. <br>\n",
    "body p.outer-text — finds any p tags with a class of outer-text inside of a body tag. <br>\n",
    "\n",
    "You can find a complete list of selectors here https://developer.mozilla.org/en-US/docs/Web/Guide/CSS/Getting_started/Selectors\n",
    "\n",
    "BeautifulSoup objects support searching a page via CSS selectors using the select method. We can use CSS selectors to find all the p tags in our page that are inside of a div like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>This domain is for use in illustrative examples in documents. You may use this\n",
       "     domain in literature without prior coordination or asking for permission.</p>,\n",
       " <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"div p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Example - Weather data\n",
    "\n",
    "We will now put this in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#page = requests.get(\"http://forecast.weather.gov/MapClick.php?lat=37.7772&lon=-122.4168\")\n",
    "url = \"http://forecast.weather.gov/MapClick.php?lat=37.7772&lon=-122.4168\"\n",
    "headers = {'User-Agent' : 'OpenGraph Extractor (YOUR_EMAIL_HERE)'}\n",
    "url = requests.get(url)#, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spoup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-1f280e1524ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdescription_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'meta'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproperty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'og:description'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdescription_node\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdescription\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdescription_node\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spoup' is not defined"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(url.content, 'html.parser')\n",
    "description_node = spoup.find('meta', property = 'og:description')\n",
    "if description_node:\n",
    "    description = description_node.get('content')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the element of your interest. You will find the source code \"blocks\" are related to the html content. Load that content in an object.\n",
    "\n",
    "![Inspecting_source_code](inspecting1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Inspectingsource_code](inspecting3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seven_day = soup.find(id=\"seven-day-forecast\")\n",
    "seven_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the \"seven_day\" object, you can select as well one of the specific elements within it. Identify them withe the name for this particular case as \"tombstone-container\".\n",
    "\n",
    "![Inspectingsource_code](inspecting4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_items = seven_day.find_all(class_=\"tombstone-container\")\n",
    "forecast_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"seven_day\" is composed by all this sub elements in the block:\n",
    "seven_day.find_all('p', attrs={'class' : 'period-name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is another way to doing it in a more elegant way\n",
    "period_tags = seven_day.select(\".tombstone-container .period-name\")\n",
    "periods = [pt.get_text() for pt in period_tags]\n",
    "periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve the first element \"tonight\"\n",
    "tonight = forecast_items[0]\n",
    "tonight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort properly with prettyfy\n",
    "print(tonight.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the specific text for each class\n",
    "period = tonight.find(class_=\"period-name\").get_text()\n",
    "short_desc = tonight.find(class_=\"short-desc\").get_text()\n",
    "temp = tonight.find(class_=\"temp\").get_text()\n",
    "\n",
    "print(period)\n",
    "print(short_desc)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the specific text for each class in a loop for the whole \"seven_day\"'s object\n",
    "short_descs = [sd.get_text() for sd in seven_day.select(\".tombstone-container .short-desc\")]\n",
    "temps = [t.get_text() for t in seven_day.select(\".tombstone-container .temp\")]\n",
    "descs = [d[\"title\"] for d in seven_day.select(\".tombstone-container img\")]\n",
    "\n",
    "print(short_descs)\n",
    "print(temps)\n",
    "print(descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put all your columns in a single data frame and give it headers\n",
    "weather = pd.DataFrame({\n",
    "        \"period\": periods, \n",
    "        \"short_desc\": short_descs, \n",
    "        \"temp\": temps, \n",
    "        \"desc\":descs\n",
    "    })\n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use regular expressions to clean the temperature as an integer\n",
    "temp_nums = weather[\"temp\"].str.extract(\"(?P<temp_num>\\d+)\", expand=False)\n",
    "weather[\"temp_num\"] = temp_nums.astype('int')\n",
    "temp_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather[\"temp_num\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_night = weather[\"temp\"].str.contains(\"Low\")\n",
    "weather[\"is_night\"] = is_night\n",
    "is_night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather[is_night]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "#### 1. Get the current weather information\n",
    "![Inspectingsource_code](inspecting5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Get the details of the current forecast\n",
    "![Inspectingsource_code](inspecting6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Get information about financial stocks\n",
    "![bloomberg](inspecting7.png)\n",
    "\n",
    "https://www.bloomberg.com/quote/SPX:IND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_page = ['http://www.bloomberg.com/quote/SPX:IND', 'http://www.bloomberg.com/quote/CCMP:IND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for pg in quote_page:\n",
    "    # query the website and return the html to the variable ‘page’\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    # parse the html using beautiful soap and store in variable `soup`\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    # Take out the <div> of name and get its value in a variable \"name\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    # get the index price in a variable \"price\"\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    # save the data in tuple\n",
    "    data.append((name, price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Get information about financial stocks.\n",
    "\n",
    "Get EUR/GBP, GBP/USD, EUR/JPY, USD/JPY\n",
    "![bloomberg](inspecting8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
