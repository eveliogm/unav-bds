{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google image download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google_images_download\n",
      "  Downloading google_images_download-2.8.0.tar.gz (14 kB)\n",
      "Requirement already satisfied: selenium in /Users/danielmarchan/opt/anaconda3/lib/python3.8/site-packages (from google_images_download) (3.141.0)\n",
      "Requirement already satisfied: urllib3 in /Users/danielmarchan/opt/anaconda3/lib/python3.8/site-packages (from selenium->google_images_download) (1.25.9)\n",
      "Building wheels for collected packages: google-images-download\n",
      "  Building wheel for google-images-download (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-images-download: filename=google_images_download-2.8.0-py2.py3-none-any.whl size=14550 sha256=03a452797593d89cffda2678059214d09e36094f506bf09dbac9177bbd558378\n",
      "  Stored in directory: /Users/danielmarchan/Library/Caches/pip/wheels/09/09/00/7a4b1a816f726438cb51067db23c7f9efedf009b6a1bfa027a\n",
      "Successfully built google-images-download\n",
      "Installing collected packages: google-images-download\n",
      "Successfully installed google-images-download-2.8.0\n"
     ]
    }
   ],
   "source": [
    "#First install the repository\n",
    "!pip install google_images_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item no.: 1 --> Item name = Polar bears\n",
      "Evaluating...\n",
      "Starting Download...\n",
      "\n",
      "\n",
      "Unfortunately all 5 could not be downloaded because some images were not downloadable. 0 is all we got for this search filter!\n",
      "\n",
      "Errors: 0\n",
      "\n",
      "({'Polar bears': []}, 0)\n"
     ]
    }
   ],
   "source": [
    "from google_images_download import google_images_download\n",
    "\n",
    "#Create the google_image_dowload class (class instantiation)\n",
    "response = google_images_download.googleimagesdownload()\n",
    "\n",
    "#creating list of arguments\n",
    "keywords = \"Polar bears\"\n",
    "limit = 5\n",
    "cd = \"/Users/danielmarchan/Documents/MasterBigData/RecogidaDatos/Session3/Images/chromedriver\"\n",
    "arguments = {\"keywords\":keywords,\"limit\":limit,\"print_urls\":True, \"chromedriver\":cd}\n",
    "\n",
    "\n",
    "paths = response.download(arguments)   #passing the arguments to the function\n",
    "print(paths)   #printing absolute paths of the downloaded images\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code from this repo does not work anymore. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/hardikvasa/google-images-download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, there is no official solution, for now, I will try to use some temporary solution that was provided in the discussions. I think Google is changing the DOM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  I will use a different branch of the same repository that says it \"fixed\" this bug "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the terminal do the following:\n",
    "######  Uninstall the old version \n",
    "pip uninstall google_images_download\n",
    "###### Download this branch \n",
    "git clone https://github.com/Joeclinton1/google-images-download.git\n",
    "###### Install all the dependencies\n",
    "cd google-images-download && sudo python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_images_download import google_images_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item no.: 1 --> Item name = bears\n",
      "Evaluating...\n",
      "Starting Download...\n",
      "\n",
      "\n",
      "Unfortunately all 100 could not be downloaded because some images were not downloadable. 0 is all we got for this search filter!\n",
      "\n",
      "Errors: 0\n",
      "\n",
      "({'bears': []}, 0)\n"
     ]
    }
   ],
   "source": [
    "#Create the google_image_dowload class (class instantiation)\n",
    "response = google_images_download.googleimagesdownload()\n",
    "\n",
    "#creating list of arguments\n",
    "keywords = \"bears\"\n",
    "limit = 100\n",
    "cd = \"/YOUR_PATH/chromedriver\"\n",
    "arguments = {\"keywords\":keywords,\"limit\":limit,\"print_urls\":True, \"chromedriver\":cd}\n",
    "\n",
    "\n",
    "paths = response.download(arguments)   #passing the arguments to the function\n",
    "print(paths)   #printing absolute paths of the downloaded images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This patched version does not work as well, same problem, issue not solved and corroborated by other users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/hardikvasa/google-images-download/issues/325#issuecomment-686552371"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New approach "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the current repository is not working I found another one as a posible solution for downloading images from Google Chrome using a similar approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/RiddlerQ/simple_image_download.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import urllib\n",
    "import requests\n",
    "import magic#python-magic is a Python interface to the libmagic file type identification library\n",
    "import progressbar\n",
    "from urllib.parse import quote\n",
    "\n",
    "class simple_image_download:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def urls(self, keywords, limit, extensions={'.jpg', '.png', '.ico', '.gif', '.jpeg'}):\n",
    "        #The string received is converted into a list of keywords\n",
    "        keyword_to_search = [str(item).strip() for item in keywords.split(',')]\n",
    "        i = 0\n",
    "        links = []\n",
    "\n",
    "        things = len(keyword_to_search) * limit\n",
    "\n",
    "        #Instantiate the progress bar for the downloading status\n",
    "        bar = progressbar.ProgressBar(maxval=things, \\\n",
    "                                      widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()]).start()\n",
    "\n",
    "        #For each keyword encoded it and create the url\n",
    "        while i < len(keyword_to_search):\n",
    "            #It iters the number of keywords you introduce\n",
    "            url = 'https://www.google.com/search?q=' + quote(\n",
    "                keyword_to_search[i].encode(\n",
    "                    'utf-8')) + '&biw=1536&bih=674&tbm=isch&sxsrf=ACYBGNSXXpS6YmAKUiLKKBs6xWb4uUY5gA:1581168823770&source=lnms&sa=X&ved=0ahUKEwioj8jwiMLnAhW9AhAIHbXTBMMQ_AUI3QUoAQ'\n",
    "            \n",
    "            #Obtain the raw_html of the image to download from it the actual image\n",
    "            raw_html = self._download_page(url)\n",
    "\n",
    "            end_object = -1;\n",
    "            google_image_seen = False;\n",
    "            j = 0\n",
    "\n",
    "            while j < limit:\n",
    "                #Iters the number of pictures you want to download\n",
    "                while (True):\n",
    "                    #This will iter until the url is perfect for the requests\n",
    "                    try:\n",
    "                        new_line = raw_html.find('\"https://', end_object + 1)\n",
    "                        end_object = raw_html.find('\"', new_line + 1)\n",
    "\n",
    "                        buffor = raw_html.find('\\\\', new_line + 1, end_object)\n",
    "                        if buffor != -1:\n",
    "                            object_raw = (raw_html[new_line + 1:buffor])\n",
    "                        else:\n",
    "                            object_raw = (raw_html[new_line + 1:end_object])\n",
    "\n",
    "                        if any(extension in object_raw for extension in extensions):\n",
    "                            break\n",
    "\n",
    "                    except Exception as e:\n",
    "                        break\n",
    "\n",
    "                #With the url try to make the request using the import request package object \n",
    "                try:\n",
    "                    #load the page\n",
    "                    r = requests.get(object_raw, allow_redirects=True, timeout=1)\n",
    "                    if('html' not in str(r.content)):\n",
    "                        mime = magic.Magic(mime=True)\n",
    "                        \n",
    "                        file_type = mime.from_buffer(r.content)\n",
    "                        file_extension = f'.{file_type.split(\"/\")[1]}'\n",
    "                        if file_extension == '.png' and not google_image_seen:\n",
    "                            google_image_seen = True\n",
    "                            raise ValueError();\n",
    "                        links.append(object_raw)\n",
    "                        bar.update(bar.currval + 1)\n",
    "                    else:\n",
    "                        j -= 1\n",
    "                except Exception as e:\n",
    "                    j -= 1\n",
    "                j += 1\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        bar.finish()\n",
    "        return(links)\n",
    "\n",
    "    #This is the method used to download the images\n",
    "    def download(self, keywords, limit, extensions={'.jpg', '.png', '.ico', '.gif', '.jpeg'}, main_directory = \"simple_images/\"):\n",
    "        #The string received is converted into a list of keywords\n",
    "        keyword_to_search = [str(item).strip() for item in keywords.split(',')]\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        things = len(keyword_to_search) * limit\n",
    "        \n",
    "        #Instantiate the progress bar for the downloading status\n",
    "        bar = progressbar.ProgressBar(maxval=things, \\\n",
    "                                      widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "        #Start the download process\n",
    "        bar.start()\n",
    "        \n",
    "        #For each keyword encoded it, create the url and crate a directory\n",
    "        while i < len(keyword_to_search):\n",
    "            self._create_directories(main_directory, keyword_to_search[i])\n",
    "            url = 'https://www.google.com/search?q=' + quote(\n",
    "                keyword_to_search[i].encode('utf-8')) + '&biw=1536&bih=674&tbm=isch&sxsrf=ACYBGNSXXpS6YmAKUiLKKBs6xWb4uUY5gA:1581168823770&source=lnms&sa=X&ved=0ahUKEwioj8jwiMLnAhW9AhAIHbXTBMMQ_AUI3QUoAQ'\n",
    "            \n",
    "            #Obtain the raw_html of the image to download from it the actual image\n",
    "            raw_html = self._download_page(url)\n",
    "\n",
    "            end_object = -1;\n",
    "            google_image_seen = False;\n",
    "            j = 0\n",
    "            \n",
    "            while j < limit:\n",
    "                #Iters the number of pictures you want to download\n",
    "                while (True):\n",
    "                    try:\n",
    "                        #This will iter until the url is perfect for the requests\n",
    "                        new_line = raw_html.find('\"https://', end_object + 1)\n",
    "                        end_object = raw_html.find('\"', new_line + 1)\n",
    "                        buffor = raw_html.find('\\\\', new_line + 1, end_object)\n",
    "                        if buffor != -1:\n",
    "                            object_raw = (raw_html[new_line+1:buffor])\n",
    "                        else:\n",
    "                            object_raw = (raw_html[new_line+1:end_object])\n",
    "\n",
    "                        if any(extension in object_raw for extension in extensions):\n",
    "                            break\n",
    "\n",
    "                    except Exception as e:\n",
    "                        break\n",
    "                path = main_directory + keyword_to_search[i].replace(\" \", \"_\")\n",
    "\n",
    "                #With the url try to make the request using the import request package object \n",
    "                try:\n",
    "                    #Load the page with the url\n",
    "                    r = requests.get(object_raw, allow_redirects=True, timeout=1)\n",
    "                    \n",
    "                    if('html' not in str(r.content)):\n",
    "                        mime = magic.Magic(mime=True)\n",
    "                        #Obtain the file type from the buffer of r.content\n",
    "                        file_type = mime.from_buffer(r.content)\n",
    "                        #Obtain the image extension\n",
    "                        file_extension = f'.{file_type.split(\"/\")[1]}'\n",
    "                        if file_extension not in extensions:\n",
    "                            raise ValueError()\n",
    "                        if file_extension == '.png' and not google_image_seen:\n",
    "                            google_image_seen = True\n",
    "                            raise ValueError()\n",
    "                        \n",
    "                        #Create the file name and store it in binary in the directory for each keyword\n",
    "                        file_name = str(keyword_to_search[i]) + \"_\" + str(j + 1) + file_extension\n",
    "                        with open(os.path.join(path, file_name), 'wb') as file:     \n",
    "                            file.write(r.content)\n",
    "                        bar.update(bar.currval + 1)\n",
    "                    else:\n",
    "                        j -= 1\n",
    "                except Exception as e:\n",
    "                    j -= 1\n",
    "                j += 1\n",
    "\n",
    "            i += 1\n",
    "        bar.finish()\n",
    "\n",
    "    #It creates in the main directory as many as keywords inside the string that you pass at the beginning\n",
    "    def _create_directories(self, main_directory, name):\n",
    "        name = name.replace(\" \", \"_\")\n",
    "        try:\n",
    "            if not os.path.exists(main_directory):\n",
    "                os.makedirs(main_directory)\n",
    "                time.sleep(0.2)\n",
    "                path = (name)\n",
    "                sub_directory = os.path.join(main_directory, path)\n",
    "                if not os.path.exists(sub_directory):\n",
    "                    os.makedirs(sub_directory)\n",
    "            else:\n",
    "                path = (name)\n",
    "                sub_directory = os.path.join(main_directory, path)\n",
    "                if not os.path.exists(sub_directory):\n",
    "                    os.makedirs(sub_directory)\n",
    "\n",
    "        except OSError as e:\n",
    "            if e.errno != 17:\n",
    "                raise\n",
    "            pass\n",
    "        return\n",
    "\n",
    "    #This method is used to obtain the html information\n",
    "    def _download_page(self,url):\n",
    "\n",
    "        try:\n",
    "            headers = {}\n",
    "            headers['User-Agent'] = \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36\"\n",
    "            req = urllib.request.Request(url, headers=headers)\n",
    "            resp = urllib.request.urlopen(req)\n",
    "            respData = str(resp.read())\n",
    "            return respData\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from simple_image_download import simple_image_download as simp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a normal implementation use this import, however some changes were done and are reflected in the code above.\n",
    "\n",
    "The code below will ask you for the keywords you want to search and download, for the number of pictures you want to download and where you want to store the images (if the path does not exist it creates one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords (separated by commas): messi, ronaldo, pele\n",
      "path for the dowload: football/\n",
      "Limit numbers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    }
   ],
   "source": [
    "keywords = input('Keywords (separated by commas): ')\n",
    "dic = input('path for the dowload: ')\n",
    "limit = input('Limit number: ')\n",
    "\n",
    "response = simple_image_download\n",
    "response().download(keywords, int(limit), extensions={'.jpg', '.png', '.ico', '.gif', '.jpeg'}, main_directory = dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downloading algorithm does a good job of keeping out corrupt images. However it is not ideal. There are still some chances of getting one-off corrupt image that cannot be used for processing. Below script will help clean those corrupt image files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/danielmarchan/Documents/MasterBigData/RecogidaDatos/Session3/Images/football/ronaldo\n",
      "ronaldo_1.jpeg\n",
      "ok\n",
      "ronaldo_4.jpeg\n",
      "ok\n",
      "ronaldo_5.jpeg\n",
      "ok\n",
      "ronaldo_2.jpeg\n",
      "ok\n",
      "ronaldo_3.jpeg\n",
      "ok\n",
      "/Users/danielmarchan/Documents/MasterBigData/RecogidaDatos/Session3/Images/football/messi\n",
      "messi_1.jpeg\n",
      "ok\n",
      "messi_2.jpeg\n",
      "ok\n",
      "messi_3.jpeg\n",
      "ok\n",
      "messi_4.jpeg\n",
      "ok\n",
      "messi_5.jpeg\n",
      "ok\n",
      "/Users/danielmarchan/Documents/MasterBigData/RecogidaDatos/Session3/Images/football/pele\n",
      "pele_1.jpeg\n",
      "ok\n",
      "pele_2.jpeg\n",
      "ok\n",
      "pele_3.jpeg\n",
      "ok\n",
      "pele_4.jpeg\n",
      "ok\n",
      "pele_5.jpeg\n",
      "ok\n",
      "/Users/danielmarchan/Documents/MasterBigData/RecogidaDatos/Session3/Images/football/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path_dir = '/Users/danielmarchan/Documents/MasterBigData/RecogidaDatos/Session3/Images/football/'\n",
    "\n",
    "for nom_dir, dirs, ficheros in os.walk(path_dir, topdown=False):\n",
    "    print(nom_dir)\n",
    "    for nombre_fichero in ficheros:\n",
    "        print(nombre_fichero)\n",
    "        try :\n",
    "            with Image.open(nom_dir + \"/\" + nombre_fichero) as im:\n",
    "                 print('ok')\n",
    "        except :\n",
    "            print(nom_dir + \"/\" + nombre_fichero)\n",
    "            os.remove(nom_dir + \"/\" + nombre_fichero)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
