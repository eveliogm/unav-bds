{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQM7oRc6eMui"
   },
   "source": [
    "# Python para el análisis de datos -  UNAV 2020-2021\n",
    "---\n",
    "\n",
    "# Proyecto Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JTD7SzHeMu-"
   },
   "source": [
    "Este año, la nota final se evaluará teniendo en cuenta un pequeño proyecto.\n",
    "Este proyecto se realizará por parejas. Estas parejas no podrán haber estudiado juntos o estar en el mismo equipo a nivel laboral.\n",
    " \n",
    "\n",
    "El proyecto consistirá en ser capaces de bajar la cotización de un par de monedas, un ejemplo de cotizaciones en Kraken:\n",
    "https://www.kraken.com/es-es/prices?quote=EUR\n",
    "\n",
    "Después de bajarlas, será necesario hacer una gráfica del movimiento que ha tenido.\n",
    "\n",
    "Además, se hará una gráfica de la media móvil:\n",
    "https://www.rankia.com/diccionario/trading/medias-moviles\n",
    "\n",
    "La entrega final consistirá como mínimo en:\n",
    "\n",
    "- Una memoria, la memoria será el contenido principal de la entrega.\n",
    "- Código, excluida cualquier librería adicional. Este código será material auxiliar para la corrección pero será obligado que también esté presente en la entrega.\n",
    "\n",
    "Puntos mínimos:\n",
    "\n",
    "- Lectura y representación del movimiento del par de monedas - Máximo (4 puntos)\n",
    "    - Descargar datos. Máximo (2 puntos)  \n",
    "        - Utilizando la librería Kraken (2 puntos).\n",
    "          https://github.com/veox/python3-krakenex\n",
    "        - Utilizando descarga directa a través de Pandas (1 punto).\n",
    "          https://drive.google.com/uc?id=1eQsiD8Z8wEt1mx9VICzCmIEQufWjaUD-\n",
    "        - Descargar directamente y utilizar el csv en local (0 puntos).\n",
    "    - Graficar cotizaciones. Máximo (2 puntos).\n",
    "        - Graficar el par ETH/USDT (1 punto).\n",
    "        - Input de usuario que permita graficar cualquier cotización o una a elegir en el menú (2 puntos).\n",
    "\n",
    "- Indicadores técnicos. Máximo (3 puntos).\n",
    "    - Calcular el Media Móvil y graficarla (1 puntos).\n",
    "    - Calcular el RSI y graficarlo (1 puntos).\n",
    "    - Graficar el Media Móvil junto con la cotización del par calculado (1 punto).\n",
    "\n",
    "- Estructuración. Máximo (1 punto)\n",
    "    - Funciones (0,5 puntos)\n",
    "    - Utilización de clases (0,5 puntos)\n",
    "    - Manejo de errores y excepciones (0,5 puntos)\n",
    "\n",
    "- Memoria obligatoria. Máximo (2 puntos).\n",
    "    - Descripción de cómo se ha afrontado el proyecto y por qué.\n",
    "    - Descripción detallada de cada uno de los puntos que se evalúan.\n",
    "    - Descripción de la estructura del código y estructura de ficheros.\n",
    "    - Descripción de la forma de ejecución del código.\n",
    "    - Pantallazos de todo Aquel punto que requiera algún tipo de visualización.\n",
    "    - NADA QUE NO SE PUEDA ENCONTRAR DESCRITO O MOSTRADO EN LA MEMORIA SERÁ EVALUADO, AUNQUE ESTÉ REALIZADO EN EL CÓDIGO.\n",
    "\n",
    "- Puntación Extra. Máximo (1 punto)\n",
    "    - Testeo y cobertura (unit-testing, integration-testing) 0,25 puntos\n",
    "    - Facilitar los mecanismos para la reproducción del entorno virtual (ya sea con Poetry, Pipenv o pip) 0,25 puntos\n",
    "    - Distribución del proyecto a través de PyPi o una plataforma PaaS (AWS, Heroku, etc) 0,25 puntos\n",
    "\n",
    "La plazo de entrega finalizará el 29 de diciembre a las 23:59."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = \"W/qGZGYHY1HiaOf6H/EcpiNKm7CvCm2/6FKMnheoARtek+v6mfvk2Q8Q\"\n",
    "PRIVATE_KEY = \"6FytyFCHM93th6CFlAoH5sEoHpcQGslty//Axld1BusMRZsHm/ny9NG2RZE20AenGM47oXTTm5E5jcr38EpSug==\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import krakenex\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalHashError",
     "evalue": "module '__main__' has no attribute '__file__'\n\nWhile caching the body of `get_data()`, Streamlit encountered an\nobject of type `builtins.function`, which it does not know how to hash.\n\n**In this specific case, it's very likely you found a Streamlit bug so please\n[file a bug report here.]\n(https://github.com/streamlit/streamlit/issues/new/choose)**\n\nIn the meantime, you can try bypassing this error by registering a custom\nhash function via the `hash_funcs` keyword in @st.cache(). For example:\n\n```\n@st.cache(hash_funcs={builtins.function: my_hash_func})\ndef my_func(...):\n    ...\n```\n\nIf you don't know where the object of type `builtins.function` is coming\nfrom, try looking at the hash chain below for an object that you do recognize,\nthen pass that to `hash_funcs` instead:\n\n```\nObject of type builtins.function: <function get_data at 0x7f9dd97e7eb0>\n```\n\nPlease see the `hash_funcs` [documentation]\n(https://docs.streamlit.io/library/advanced-features/caching#the-hash_funcs-parameter)\nfor more details.\n            ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/unav00/lib/python3.10/site-packages/streamlit/runtime/legacy_caching/hashing.py:360\u001b[0m, in \u001b[0;36m_CodeHasher.to_bytes\u001b[0;34m(self, obj, context)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# Hash the input\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (tname, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# Hmmm... It's possible that the size calculation is wrong. When we\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;66;03m# call to_bytes inside _to_bytes things get double-counted.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/unav00/lib/python3.10/site-packages/streamlit/runtime/legacy_caching/hashing.py:626\u001b[0m, in \u001b[0;36m_CodeHasher._to_bytes\u001b[0;34m(self, obj, context)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m code \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file_should_be_hashed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_filename\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    627\u001b[0m     context \u001b[38;5;241m=\u001b[39m _get_context(obj)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/unav00/lib/python3.10/site-packages/streamlit/runtime/legacy_caching/hashing.py:402\u001b[0m, in \u001b[0;36m_CodeHasher._file_should_be_hashed\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_is_in_folder_glob(\n\u001b[0;32m--> 402\u001b[0m     filepath, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_main_script_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    403\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_in_pythonpath(filepath)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/unav00/lib/python3.10/site-packages/streamlit/runtime/legacy_caching/hashing.py:714\u001b[0m, in \u001b[0;36m_CodeHasher._get_main_script_directory\u001b[0;34m()\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;66;03m# This works because we set __main__.__file__ to the\u001b[39;00m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# script path in ScriptRunner.\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m abs_main_path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(\u001b[43m__main__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__file__\u001b[39;49m)\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(abs_main_path\u001b[38;5;241m.\u001b[39mparent)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module '__main__' has no attribute '__file__'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalHashError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [71], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m],unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m----> 7\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/unav00/lib/python3.10/site-packages/streamlit/runtime/legacy_caching/caching.py:624\u001b[0m, in \u001b[0;36mcache.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_spinner:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m spinner(message):\n\u001b[0;32m--> 624\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_or_create_cached_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_or_create_cached_value()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/unav00/lib/python3.10/site-packages/streamlit/runtime/legacy_caching/caching.py:549\u001b[0m, in \u001b[0;36mcache.<locals>.wrapped_func.<locals>.get_or_create_cached_value\u001b[0;34m()\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m cache_key\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;66;03m# Delay generating the cache key until the first call.\u001b[39;00m\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;66;03m# This way we can see values of globals, including functions\u001b[39;00m\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;66;03m# defined after this one.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;66;03m# If we generated the key earlier we would only hash those\u001b[39;00m\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;66;03m# globals by name, and miss changes in their code or value.\u001b[39;00m\n\u001b[0;32m--> 549\u001b[0m     cache_key \u001b[38;5;241m=\u001b[39m \u001b[43m_hash_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnon_optional_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_funcs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;66;03m# First, get the cache that's attached to this function.\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;66;03m# This cache's key is generated (above) from the function's code.\u001b[39;00m\n\u001b[1;32m    553\u001b[0m mem_cache \u001b[38;5;241m=\u001b[39m _mem_caches\u001b[38;5;241m.\u001b[39mget_cache(cache_key, max_entries, ttl)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/unav00/lib/python3.10/site-packages/streamlit/runtime/legacy_caching/caching.py:676\u001b[0m, in \u001b[0;36m_hash_func\u001b[0;34m(func, hash_funcs)\u001b[0m\n\u001b[1;32m    665\u001b[0m update_hash(\n\u001b[1;32m    666\u001b[0m     (func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m),\n\u001b[1;32m    667\u001b[0m     hasher\u001b[38;5;241m=\u001b[39mfunc_hasher,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    670\u001b[0m     hash_source\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    671\u001b[0m )\n\u001b[1;32m    673\u001b[0m \u001b[38;5;66;03m# Include the function's body in the hash. We *do* pass hash_funcs here,\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;66;03m# because this step will be hashing any objects referenced in the function\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;66;03m# body.\u001b[39;00m\n\u001b[0;32m--> 676\u001b[0m \u001b[43mupdate_hash\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhasher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_hasher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhash_funcs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhash_funcs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhash_reason\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHashReason\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCACHING_FUNC_BODY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhash_source\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    683\u001b[0m cache_key \u001b[38;5;241m=\u001b[39m func_hasher\u001b[38;5;241m.\u001b[39mhexdigest()\n\u001b[1;32m    684\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmem_cache key for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, cache_key\n\u001b[1;32m    686\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/unav00/lib/python3.10/site-packages/streamlit/runtime/legacy_caching/hashing.py:108\u001b[0m, in \u001b[0;36mupdate_hash\u001b[0;34m(val, hasher, hash_reason, hash_source, context, hash_funcs)\u001b[0m\n\u001b[1;32m    105\u001b[0m hash_stacks\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mhash_source \u001b[38;5;241m=\u001b[39m hash_source\n\u001b[1;32m    107\u001b[0m ch \u001b[38;5;241m=\u001b[39m _CodeHasher(hash_funcs)\n\u001b[0;32m--> 108\u001b[0m \u001b[43mch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhasher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/unav00/lib/python3.10/site-packages/streamlit/runtime/legacy_caching/hashing.py:385\u001b[0m, in \u001b[0;36m_CodeHasher.update\u001b[0;34m(self, hasher, obj, context)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, hasher, obj: Any, context: Optional[Context] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124;03m\"\"\"Update the provided hasher with the hash of an object.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m     hasher\u001b[38;5;241m.\u001b[39mupdate(b)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/unav00/lib/python3.10/site-packages/streamlit/runtime/legacy_caching/hashing.py:374\u001b[0m, in \u001b[0;36m_CodeHasher.to_bytes\u001b[0;34m(self, obj, context)\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m--> 374\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InternalHashError(ex, obj)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;66;03m# In case an UnhashableTypeError (or other) error is thrown, clean up the\u001b[39;00m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;66;03m# stack so we don't get false positives in future hashing calls\u001b[39;00m\n\u001b[1;32m    379\u001b[0m     hash_stacks\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mpop()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/unav00/lib/python3.10/site-packages/streamlit/runtime/legacy_caching/hashing.py:360\u001b[0m, in \u001b[0;36m_CodeHasher.to_bytes\u001b[0;34m(self, obj, context)\u001b[0m\n\u001b[1;32m    356\u001b[0m hash_stacks\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mpush(obj)\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# Hash the input\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (tname, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# Hmmm... It's possible that the size calculation is wrong. When we\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;66;03m# call to_bytes inside _to_bytes things get double-counted.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mgetsizeof(b)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/unav00/lib/python3.10/site-packages/streamlit/runtime/legacy_caching/hashing.py:626\u001b[0m, in \u001b[0;36m_CodeHasher._to_bytes\u001b[0;34m(self, obj, context)\u001b[0m\n\u001b[1;32m    624\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__code__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m code \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file_should_be_hashed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_filename\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    627\u001b[0m     context \u001b[38;5;241m=\u001b[39m _get_context(obj)\n\u001b[1;32m    628\u001b[0m     defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__defaults__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/unav00/lib/python3.10/site-packages/streamlit/runtime/legacy_caching/hashing.py:402\u001b[0m, in \u001b[0;36m_CodeHasher._file_should_be_hashed\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_is_blacklisted:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_is_in_folder_glob(\n\u001b[0;32m--> 402\u001b[0m     filepath, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_main_script_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    403\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m file_util\u001b[38;5;241m.\u001b[39mfile_in_pythonpath(filepath)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/unav00/lib/python3.10/site-packages/streamlit/runtime/legacy_caching/hashing.py:714\u001b[0m, in \u001b[0;36m_CodeHasher._get_main_script_directory\u001b[0;34m()\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01m__main__\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;66;03m# This works because we set __main__.__file__ to the\u001b[39;00m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# script path in ScriptRunner.\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m abs_main_path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(\u001b[43m__main__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__file__\u001b[39;49m)\u001b[38;5;241m.\u001b[39mresolve()\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(abs_main_path\u001b[38;5;241m.\u001b[39mparent)\n",
      "\u001b[0;31mInternalHashError\u001b[0m: module '__main__' has no attribute '__file__'\n\nWhile caching the body of `get_data()`, Streamlit encountered an\nobject of type `builtins.function`, which it does not know how to hash.\n\n**In this specific case, it's very likely you found a Streamlit bug so please\n[file a bug report here.]\n(https://github.com/streamlit/streamlit/issues/new/choose)**\n\nIn the meantime, you can try bypassing this error by registering a custom\nhash function via the `hash_funcs` keyword in @st.cache(). For example:\n\n```\n@st.cache(hash_funcs={builtins.function: my_hash_func})\ndef my_func(...):\n    ...\n```\n\nIf you don't know where the object of type `builtins.function` is coming\nfrom, try looking at the hash chain below for an object that you do recognize,\nthen pass that to `hash_funcs` instead:\n\n```\nObject of type builtins.function: <function get_data at 0x7f9dd97e7eb0>\n```\n\nPlease see the `hash_funcs` [documentation]\n(https://docs.streamlit.io/library/advanced-features/caching#the-hash_funcs-parameter)\nfor more details.\n            "
     ]
    }
   ],
   "source": [
    "@st.cache\n",
    "def get_data():\n",
    "    ret = kraken.query_public('OHLC', data = {'pair': pair, 'since': since, 'interval':interval})\n",
    "    data = pd.DataFrame(ret[\"result\"][\"XETHZEUR\"],columns=ticks_schema)\n",
    "    data[\"time\"] = pd.to_datetime(data['time'],unit='s')\n",
    "    return data\n",
    "df = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2022-11-18 23:15:00\n",
       "1     2022-11-18 23:30:00\n",
       "2     2022-11-18 23:45:00\n",
       "3     2022-11-19 00:00:00\n",
       "4     2022-11-19 00:15:00\n",
       "              ...        \n",
       "141   2022-11-20 10:30:00\n",
       "142   2022-11-20 10:45:00\n",
       "143   2022-11-20 11:00:00\n",
       "144   2022-11-20 11:15:00\n",
       "145   2022-11-20 11:30:00\n",
       "Name: time, Length: 146, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- convert to utc\n",
    "- set an interval variable\n",
    "- set a since variable wiht up to 720 bins. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
